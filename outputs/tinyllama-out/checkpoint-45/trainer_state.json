{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.825396825396825,
  "eval_steps": 500,
  "global_step": 45,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06349206349206349,
      "grad_norm": 0.15296223759651184,
      "learning_rate": 0.0,
      "loss": 0.2636,
      "step": 1
    },
    {
      "epoch": 0.12698412698412698,
      "grad_norm": 0.18119879066944122,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.2943,
      "step": 2
    },
    {
      "epoch": 0.19047619047619047,
      "grad_norm": 0.2529992163181305,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.4737,
      "step": 3
    },
    {
      "epoch": 0.25396825396825395,
      "grad_norm": 0.1954917460680008,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.4744,
      "step": 4
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 0.14418582618236542,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.3567,
      "step": 5
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 0.16116571426391602,
      "learning_rate": 0.00011111111111111112,
      "loss": 0.3656,
      "step": 6
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.13737976551055908,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.2606,
      "step": 7
    },
    {
      "epoch": 0.5079365079365079,
      "grad_norm": 0.1185978353023529,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.278,
      "step": 8
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.13818487524986267,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.3762,
      "step": 9
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 0.13906411826610565,
      "learning_rate": 0.0002,
      "loss": 0.2403,
      "step": 10
    },
    {
      "epoch": 0.6984126984126984,
      "grad_norm": 0.1204458549618721,
      "learning_rate": 0.00019992479525042303,
      "loss": 0.1822,
      "step": 11
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 0.12928557395935059,
      "learning_rate": 0.0001996992941167792,
      "loss": 0.1095,
      "step": 12
    },
    {
      "epoch": 0.8253968253968254,
      "grad_norm": 0.17519935965538025,
      "learning_rate": 0.00019932383577419432,
      "loss": 0.243,
      "step": 13
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.12805482745170593,
      "learning_rate": 0.00019879898494768093,
      "loss": 0.1898,
      "step": 14
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.12770533561706543,
      "learning_rate": 0.00019812553106273847,
      "loss": 0.1359,
      "step": 15
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10365331918001175,
      "learning_rate": 0.00019730448705798239,
      "loss": 0.0983,
      "step": 16
    },
    {
      "epoch": 1.0634920634920635,
      "grad_norm": 0.2158232480287552,
      "learning_rate": 0.00019633708786158806,
      "loss": 0.13,
      "step": 17
    },
    {
      "epoch": 1.126984126984127,
      "grad_norm": 0.1355675309896469,
      "learning_rate": 0.00019522478853384155,
      "loss": 0.1509,
      "step": 18
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.11774076521396637,
      "learning_rate": 0.00019396926207859084,
      "loss": 0.1249,
      "step": 19
    },
    {
      "epoch": 1.253968253968254,
      "grad_norm": 0.15101665258407593,
      "learning_rate": 0.00019257239692688907,
      "loss": 0.1901,
      "step": 20
    },
    {
      "epoch": 1.3174603174603174,
      "grad_norm": 0.10558690130710602,
      "learning_rate": 0.0001910362940966147,
      "loss": 0.1407,
      "step": 21
    },
    {
      "epoch": 1.380952380952381,
      "grad_norm": 0.11926873028278351,
      "learning_rate": 0.00018936326403234125,
      "loss": 0.0959,
      "step": 22
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 0.10183214396238327,
      "learning_rate": 0.0001875558231302091,
      "loss": 0.1852,
      "step": 23
    },
    {
      "epoch": 1.507936507936508,
      "grad_norm": 0.09349608421325684,
      "learning_rate": 0.00018561668995302667,
      "loss": 0.078,
      "step": 24
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.12548023462295532,
      "learning_rate": 0.00018354878114129367,
      "loss": 0.1395,
      "step": 25
    },
    {
      "epoch": 1.6349206349206349,
      "grad_norm": 0.11854147911071777,
      "learning_rate": 0.00018135520702629675,
      "loss": 0.1975,
      "step": 26
    },
    {
      "epoch": 1.6984126984126984,
      "grad_norm": 0.08729469776153564,
      "learning_rate": 0.00017903926695187595,
      "loss": 0.1414,
      "step": 27
    },
    {
      "epoch": 1.7619047619047619,
      "grad_norm": 0.09988831728696823,
      "learning_rate": 0.0001766044443118978,
      "loss": 0.0789,
      "step": 28
    },
    {
      "epoch": 1.8253968253968254,
      "grad_norm": 0.10587123036384583,
      "learning_rate": 0.00017405440131090048,
      "loss": 0.0963,
      "step": 29
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.0954623594880104,
      "learning_rate": 0.00017139297345578994,
      "loss": 0.0929,
      "step": 30
    },
    {
      "epoch": 1.9523809523809523,
      "grad_norm": 0.09315904229879379,
      "learning_rate": 0.0001686241637868734,
      "loss": 0.1027,
      "step": 31
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.12930479645729065,
      "learning_rate": 0.0001657521368569064,
      "loss": 0.1293,
      "step": 32
    },
    {
      "epoch": 2.0634920634920633,
      "grad_norm": 0.08818369358778,
      "learning_rate": 0.00016278121246720987,
      "loss": 0.0836,
      "step": 33
    },
    {
      "epoch": 2.126984126984127,
      "grad_norm": 0.08931903541088104,
      "learning_rate": 0.00015971585917027862,
      "loss": 0.1135,
      "step": 34
    },
    {
      "epoch": 2.1904761904761907,
      "grad_norm": 0.0965527594089508,
      "learning_rate": 0.00015656068754865387,
      "loss": 0.1135,
      "step": 35
    },
    {
      "epoch": 2.253968253968254,
      "grad_norm": 0.08637815713882446,
      "learning_rate": 0.00015332044328016914,
      "loss": 0.0729,
      "step": 36
    },
    {
      "epoch": 2.317460317460317,
      "grad_norm": 0.09747080504894257,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.0828,
      "step": 37
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.1116548553109169,
      "learning_rate": 0.0001466043519702539,
      "loss": 0.1397,
      "step": 38
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.09739480167627335,
      "learning_rate": 0.00014313860656812536,
      "loss": 0.1101,
      "step": 39
    },
    {
      "epoch": 2.507936507936508,
      "grad_norm": 0.08939965069293976,
      "learning_rate": 0.0001396079766039157,
      "loss": 0.0689,
      "step": 40
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.11717621982097626,
      "learning_rate": 0.00013601777248047105,
      "loss": 0.155,
      "step": 41
    },
    {
      "epoch": 2.634920634920635,
      "grad_norm": 0.09427564591169357,
      "learning_rate": 0.00013237339420583212,
      "loss": 0.0756,
      "step": 42
    },
    {
      "epoch": 2.6984126984126986,
      "grad_norm": 0.08688991516828537,
      "learning_rate": 0.00012868032327110904,
      "loss": 0.0471,
      "step": 43
    },
    {
      "epoch": 2.761904761904762,
      "grad_norm": 0.09005856513977051,
      "learning_rate": 0.00012494411440579814,
      "loss": 0.0814,
      "step": 44
    },
    {
      "epoch": 2.825396825396825,
      "grad_norm": 0.08233162015676498,
      "learning_rate": 0.0001211703872229411,
      "loss": 0.0573,
      "step": 45
    }
  ],
  "logging_steps": 1,
  "max_steps": 90,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 15,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2317939340476416.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
