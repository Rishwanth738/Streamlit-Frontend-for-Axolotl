{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.698412698412699,
  "eval_steps": 500,
  "global_step": 90,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06349206349206349,
      "grad_norm": 0.15296223759651184,
      "learning_rate": 0.0,
      "loss": 0.2636,
      "step": 1
    },
    {
      "epoch": 0.12698412698412698,
      "grad_norm": 0.18119879066944122,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.2943,
      "step": 2
    },
    {
      "epoch": 0.19047619047619047,
      "grad_norm": 0.2529992163181305,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.4737,
      "step": 3
    },
    {
      "epoch": 0.25396825396825395,
      "grad_norm": 0.1954917460680008,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.4744,
      "step": 4
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 0.14418582618236542,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.3567,
      "step": 5
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 0.16116571426391602,
      "learning_rate": 0.00011111111111111112,
      "loss": 0.3656,
      "step": 6
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.13737976551055908,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.2606,
      "step": 7
    },
    {
      "epoch": 0.5079365079365079,
      "grad_norm": 0.1185978353023529,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.278,
      "step": 8
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.13818487524986267,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.3762,
      "step": 9
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 0.13906411826610565,
      "learning_rate": 0.0002,
      "loss": 0.2403,
      "step": 10
    },
    {
      "epoch": 0.6984126984126984,
      "grad_norm": 0.1204458549618721,
      "learning_rate": 0.00019992479525042303,
      "loss": 0.1822,
      "step": 11
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 0.12928557395935059,
      "learning_rate": 0.0001996992941167792,
      "loss": 0.1095,
      "step": 12
    },
    {
      "epoch": 0.8253968253968254,
      "grad_norm": 0.17519935965538025,
      "learning_rate": 0.00019932383577419432,
      "loss": 0.243,
      "step": 13
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.12805482745170593,
      "learning_rate": 0.00019879898494768093,
      "loss": 0.1898,
      "step": 14
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.12770533561706543,
      "learning_rate": 0.00019812553106273847,
      "loss": 0.1359,
      "step": 15
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10365331918001175,
      "learning_rate": 0.00019730448705798239,
      "loss": 0.0983,
      "step": 16
    },
    {
      "epoch": 1.0634920634920635,
      "grad_norm": 0.2158232480287552,
      "learning_rate": 0.00019633708786158806,
      "loss": 0.13,
      "step": 17
    },
    {
      "epoch": 1.126984126984127,
      "grad_norm": 0.1355675309896469,
      "learning_rate": 0.00019522478853384155,
      "loss": 0.1509,
      "step": 18
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.11774076521396637,
      "learning_rate": 0.00019396926207859084,
      "loss": 0.1249,
      "step": 19
    },
    {
      "epoch": 1.253968253968254,
      "grad_norm": 0.15101665258407593,
      "learning_rate": 0.00019257239692688907,
      "loss": 0.1901,
      "step": 20
    },
    {
      "epoch": 1.3174603174603174,
      "grad_norm": 0.10558690130710602,
      "learning_rate": 0.0001910362940966147,
      "loss": 0.1407,
      "step": 21
    },
    {
      "epoch": 1.380952380952381,
      "grad_norm": 0.11926873028278351,
      "learning_rate": 0.00018936326403234125,
      "loss": 0.0959,
      "step": 22
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 0.10183214396238327,
      "learning_rate": 0.0001875558231302091,
      "loss": 0.1852,
      "step": 23
    },
    {
      "epoch": 1.507936507936508,
      "grad_norm": 0.09349608421325684,
      "learning_rate": 0.00018561668995302667,
      "loss": 0.078,
      "step": 24
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.12548023462295532,
      "learning_rate": 0.00018354878114129367,
      "loss": 0.1395,
      "step": 25
    },
    {
      "epoch": 1.6349206349206349,
      "grad_norm": 0.11854147911071777,
      "learning_rate": 0.00018135520702629675,
      "loss": 0.1975,
      "step": 26
    },
    {
      "epoch": 1.6984126984126984,
      "grad_norm": 0.08729469776153564,
      "learning_rate": 0.00017903926695187595,
      "loss": 0.1414,
      "step": 27
    },
    {
      "epoch": 1.7619047619047619,
      "grad_norm": 0.09988831728696823,
      "learning_rate": 0.0001766044443118978,
      "loss": 0.0789,
      "step": 28
    },
    {
      "epoch": 1.8253968253968254,
      "grad_norm": 0.10587123036384583,
      "learning_rate": 0.00017405440131090048,
      "loss": 0.0963,
      "step": 29
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.0954623594880104,
      "learning_rate": 0.00017139297345578994,
      "loss": 0.0929,
      "step": 30
    },
    {
      "epoch": 1.9523809523809523,
      "grad_norm": 0.09315904229879379,
      "learning_rate": 0.0001686241637868734,
      "loss": 0.1027,
      "step": 31
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.12930479645729065,
      "learning_rate": 0.0001657521368569064,
      "loss": 0.1293,
      "step": 32
    },
    {
      "epoch": 2.0634920634920633,
      "grad_norm": 0.08818369358778,
      "learning_rate": 0.00016278121246720987,
      "loss": 0.0836,
      "step": 33
    },
    {
      "epoch": 2.126984126984127,
      "grad_norm": 0.08931903541088104,
      "learning_rate": 0.00015971585917027862,
      "loss": 0.1135,
      "step": 34
    },
    {
      "epoch": 2.1904761904761907,
      "grad_norm": 0.0965527594089508,
      "learning_rate": 0.00015656068754865387,
      "loss": 0.1135,
      "step": 35
    },
    {
      "epoch": 2.253968253968254,
      "grad_norm": 0.08637815713882446,
      "learning_rate": 0.00015332044328016914,
      "loss": 0.0729,
      "step": 36
    },
    {
      "epoch": 2.317460317460317,
      "grad_norm": 0.09747080504894257,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.0828,
      "step": 37
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.1116548553109169,
      "learning_rate": 0.0001466043519702539,
      "loss": 0.1397,
      "step": 38
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.09739480167627335,
      "learning_rate": 0.00014313860656812536,
      "loss": 0.1101,
      "step": 39
    },
    {
      "epoch": 2.507936507936508,
      "grad_norm": 0.08939965069293976,
      "learning_rate": 0.0001396079766039157,
      "loss": 0.0689,
      "step": 40
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.11717621982097626,
      "learning_rate": 0.00013601777248047105,
      "loss": 0.155,
      "step": 41
    },
    {
      "epoch": 2.634920634920635,
      "grad_norm": 0.09427564591169357,
      "learning_rate": 0.00013237339420583212,
      "loss": 0.0756,
      "step": 42
    },
    {
      "epoch": 2.6984126984126986,
      "grad_norm": 0.08688991516828537,
      "learning_rate": 0.00012868032327110904,
      "loss": 0.0471,
      "step": 43
    },
    {
      "epoch": 2.761904761904762,
      "grad_norm": 0.09005856513977051,
      "learning_rate": 0.00012494411440579814,
      "loss": 0.0814,
      "step": 44
    },
    {
      "epoch": 2.825396825396825,
      "grad_norm": 0.08233162015676498,
      "learning_rate": 0.0001211703872229411,
      "loss": 0.0573,
      "step": 45
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.0854857861995697,
      "learning_rate": 0.00011736481776669306,
      "loss": 0.0396,
      "step": 46
    },
    {
      "epoch": 2.9523809523809526,
      "grad_norm": 0.10335849225521088,
      "learning_rate": 0.00011353312997501313,
      "loss": 0.0912,
      "step": 47
    },
    {
      "epoch": 3.0634920634920633,
      "grad_norm": 0.15343505144119263,
      "learning_rate": 0.00010968108707031792,
      "loss": 0.1963,
      "step": 48
    },
    {
      "epoch": 3.126984126984127,
      "grad_norm": 0.09392039477825165,
      "learning_rate": 0.00010581448289104758,
      "loss": 0.0761,
      "step": 49
    },
    {
      "epoch": 3.1904761904761907,
      "grad_norm": 0.07784009724855423,
      "learning_rate": 0.00010193913317718244,
      "loss": 0.0587,
      "step": 50
    },
    {
      "epoch": 3.253968253968254,
      "grad_norm": 0.07661347836256027,
      "learning_rate": 9.806086682281758e-05,
      "loss": 0.0453,
      "step": 51
    },
    {
      "epoch": 3.317460317460317,
      "grad_norm": 0.07993417978286743,
      "learning_rate": 9.418551710895243e-05,
      "loss": 0.0616,
      "step": 52
    },
    {
      "epoch": 3.380952380952381,
      "grad_norm": 0.07906872779130936,
      "learning_rate": 9.03189129296821e-05,
      "loss": 0.0489,
      "step": 53
    },
    {
      "epoch": 3.4444444444444446,
      "grad_norm": 0.09634517133235931,
      "learning_rate": 8.646687002498692e-05,
      "loss": 0.0854,
      "step": 54
    },
    {
      "epoch": 3.507936507936508,
      "grad_norm": 0.08971621096134186,
      "learning_rate": 8.263518223330697e-05,
      "loss": 0.0795,
      "step": 55
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.13643448054790497,
      "learning_rate": 7.882961277705895e-05,
      "loss": 0.1043,
      "step": 56
    },
    {
      "epoch": 3.634920634920635,
      "grad_norm": 0.10456595569849014,
      "learning_rate": 7.505588559420189e-05,
      "loss": 0.0956,
      "step": 57
    },
    {
      "epoch": 3.6984126984126986,
      "grad_norm": 0.10210233181715012,
      "learning_rate": 7.131967672889101e-05,
      "loss": 0.0541,
      "step": 58
    },
    {
      "epoch": 3.761904761904762,
      "grad_norm": 0.11157552152872086,
      "learning_rate": 6.762660579416791e-05,
      "loss": 0.0982,
      "step": 59
    },
    {
      "epoch": 3.825396825396825,
      "grad_norm": 0.08568762987852097,
      "learning_rate": 6.398222751952899e-05,
      "loss": 0.0374,
      "step": 60
    },
    {
      "epoch": 3.888888888888889,
      "grad_norm": 0.10760878771543503,
      "learning_rate": 6.039202339608432e-05,
      "loss": 0.0721,
      "step": 61
    },
    {
      "epoch": 3.9523809523809526,
      "grad_norm": 0.06186363101005554,
      "learning_rate": 5.6861393431874675e-05,
      "loss": 0.0218,
      "step": 62
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.08011948317289352,
      "learning_rate": 5.339564802974615e-05,
      "loss": 0.021,
      "step": 63
    },
    {
      "epoch": 4.063492063492063,
      "grad_norm": 0.1187150701880455,
      "learning_rate": 5.000000000000002e-05,
      "loss": 0.0542,
      "step": 64
    },
    {
      "epoch": 4.1269841269841265,
      "grad_norm": 0.08058653026819229,
      "learning_rate": 4.66795567198309e-05,
      "loss": 0.0455,
      "step": 65
    },
    {
      "epoch": 4.190476190476191,
      "grad_norm": 0.09128205478191376,
      "learning_rate": 4.343931245134616e-05,
      "loss": 0.0616,
      "step": 66
    },
    {
      "epoch": 4.253968253968254,
      "grad_norm": 0.11091754585504532,
      "learning_rate": 4.028414082972141e-05,
      "loss": 0.137,
      "step": 67
    },
    {
      "epoch": 4.317460317460317,
      "grad_norm": 0.08958403021097183,
      "learning_rate": 3.721878753279017e-05,
      "loss": 0.0526,
      "step": 68
    },
    {
      "epoch": 4.380952380952381,
      "grad_norm": 0.10274688154459,
      "learning_rate": 3.424786314309365e-05,
      "loss": 0.0848,
      "step": 69
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 0.09900441765785217,
      "learning_rate": 3.137583621312665e-05,
      "loss": 0.0687,
      "step": 70
    },
    {
      "epoch": 4.507936507936508,
      "grad_norm": 0.07930681854486465,
      "learning_rate": 2.8607026544210114e-05,
      "loss": 0.0303,
      "step": 71
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.07995881885290146,
      "learning_rate": 2.594559868909956e-05,
      "loss": 0.0383,
      "step": 72
    },
    {
      "epoch": 4.634920634920634,
      "grad_norm": 0.0995061919093132,
      "learning_rate": 2.339555568810221e-05,
      "loss": 0.0522,
      "step": 73
    },
    {
      "epoch": 4.698412698412699,
      "grad_norm": 0.08863779902458191,
      "learning_rate": 2.0960733048124083e-05,
      "loss": 0.0466,
      "step": 74
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.0797114372253418,
      "learning_rate": 1.864479297370325e-05,
      "loss": 0.0439,
      "step": 75
    },
    {
      "epoch": 4.825396825396825,
      "grad_norm": 0.09458265453577042,
      "learning_rate": 1.6451218858706374e-05,
      "loss": 0.064,
      "step": 76
    },
    {
      "epoch": 4.888888888888889,
      "grad_norm": 0.08166483044624329,
      "learning_rate": 1.4383310046973365e-05,
      "loss": 0.0286,
      "step": 77
    },
    {
      "epoch": 4.9523809523809526,
      "grad_norm": 0.0818726196885109,
      "learning_rate": 1.2444176869790925e-05,
      "loss": 0.0642,
      "step": 78
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.1297542303800583,
      "learning_rate": 1.0636735967658784e-05,
      "loss": 0.0624,
      "step": 79
    },
    {
      "epoch": 5.063492063492063,
      "grad_norm": 0.09951252490282059,
      "learning_rate": 8.963705903385345e-06,
      "loss": 0.0858,
      "step": 80
    },
    {
      "epoch": 5.1269841269841265,
      "grad_norm": 0.09357672929763794,
      "learning_rate": 7.427603073110967e-06,
      "loss": 0.0836,
      "step": 81
    },
    {
      "epoch": 5.190476190476191,
      "grad_norm": 0.09742128103971481,
      "learning_rate": 6.030737921409169e-06,
      "loss": 0.0657,
      "step": 82
    },
    {
      "epoch": 5.253968253968254,
      "grad_norm": 0.07128918170928955,
      "learning_rate": 4.775211466158469e-06,
      "loss": 0.0316,
      "step": 83
    },
    {
      "epoch": 5.317460317460317,
      "grad_norm": 0.06911790370941162,
      "learning_rate": 3.662912138411967e-06,
      "loss": 0.0387,
      "step": 84
    },
    {
      "epoch": 5.380952380952381,
      "grad_norm": 0.07435362040996552,
      "learning_rate": 2.6955129420176196e-06,
      "loss": 0.0345,
      "step": 85
    },
    {
      "epoch": 5.444444444444445,
      "grad_norm": 0.10830498486757278,
      "learning_rate": 1.874468937261531e-06,
      "loss": 0.1262,
      "step": 86
    },
    {
      "epoch": 5.507936507936508,
      "grad_norm": 0.09717680513858795,
      "learning_rate": 1.201015052319099e-06,
      "loss": 0.0627,
      "step": 87
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 0.07698384672403336,
      "learning_rate": 6.761642258056978e-07,
      "loss": 0.0352,
      "step": 88
    },
    {
      "epoch": 5.634920634920634,
      "grad_norm": 0.0840364396572113,
      "learning_rate": 3.007058832207976e-07,
      "loss": 0.0384,
      "step": 89
    },
    {
      "epoch": 5.698412698412699,
      "grad_norm": 0.07076430320739746,
      "learning_rate": 7.520474957699586e-08,
      "loss": 0.0176,
      "step": 90
    }
  ],
  "logging_steps": 1,
  "max_steps": 90,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 15,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4661922943205376.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
