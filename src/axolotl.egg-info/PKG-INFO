Metadata-Version: 2.4
Name: axolotl
Version: 0.11.0.dev0
Summary: LLM Trainer
Project-URL: Homepage, https://axolotl.ai/
Project-URL: Documentation, https://docs.axolotl.ai/
Project-URL: Repository, https://github.com/axolotl-ai-cloud/axolotl.git
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: bitsandbytes==0.46.0
Requires-Dist: triton>=3.0.0
Requires-Dist: autoawq==0.2.7.post3
Requires-Dist: liger-kernel==0.5.10
Requires-Dist: packaging==23.2
Requires-Dist: huggingface_hub==0.32.2
Requires-Dist: peft==0.15.2
Requires-Dist: transformers==4.52.4
Requires-Dist: tokenizers>=0.21.1
Requires-Dist: accelerate==1.8.1
Requires-Dist: datasets==3.6.0
Requires-Dist: trl==0.18.2
Requires-Dist: hf_xet==1.1.2
Requires-Dist: optimum==1.16.2
Requires-Dist: hf_transfer
Requires-Dist: sentencepiece
Requires-Dist: gradio==5.23.3
Requires-Dist: modal==0.70.5
Requires-Dist: pydantic==2.10.6
Requires-Dist: addict
Requires-Dist: fire
Requires-Dist: PyYAML>=6.0
Requires-Dist: requests
Requires-Dist: wandb
Requires-Dist: einops
Requires-Dist: colorama
Requires-Dist: numba
Requires-Dist: numpy<=2.0.1,>=1.24.4
Requires-Dist: evaluate==0.4.1
Requires-Dist: scipy
Requires-Dist: scikit-learn==1.4.2
Requires-Dist: nvidia-ml-py==12.560.30
Requires-Dist: art
Requires-Dist: tensorboard
Requires-Dist: python-dotenv==1.0.1
Requires-Dist: s3fs>=2024.5.0
Requires-Dist: gcsfs>=2024.5.0
Requires-Dist: adlfs>=2024.5.0
Requires-Dist: ocifs==1.3.2
Requires-Dist: zstandard==0.22.0
Requires-Dist: fastcore
Requires-Dist: lm_eval==0.4.7
Requires-Dist: langdetect==1.0.9
Requires-Dist: immutabledict==4.2.0
Requires-Dist: antlr4-python3-runtime==4.13.2
Requires-Dist: torchao==0.10.0
Requires-Dist: schedulefree==1.4.1
Requires-Dist: axolotl-contribs-lgpl==0.0.6
Requires-Dist: axolotl-contribs-mit==0.0.3
Requires-Dist: mistral-common==1.6.3
Requires-Dist: torch==2.6.0
Requires-Dist: xformers==0.0.29.post2
Provides-Extra: flash-attn
Requires-Dist: flash-attn==2.8.0.post2; extra == "flash-attn"
Provides-Extra: ring-flash-attn
Requires-Dist: flash-attn==2.8.0.post2; extra == "ring-flash-attn"
Requires-Dist: ring-flash-attn>=0.1.4; extra == "ring-flash-attn"
Requires-Dist: yunchang==0.6.0; extra == "ring-flash-attn"
Provides-Extra: deepspeed
Requires-Dist: deepspeed==0.17.1; extra == "deepspeed"
Requires-Dist: deepspeed-kernels; extra == "deepspeed"
Provides-Extra: mamba-ssm
Requires-Dist: mamba-ssm==1.2.0.post1; extra == "mamba-ssm"
Requires-Dist: causal_conv1d; extra == "mamba-ssm"
Provides-Extra: auto-gptq
Requires-Dist: auto-gptq==0.5.1; extra == "auto-gptq"
Provides-Extra: mlflow
Requires-Dist: mlflow; extra == "mlflow"
Provides-Extra: galore
Requires-Dist: galore_torch; extra == "galore"
Provides-Extra: apollo
Requires-Dist: apollo-torch; extra == "apollo"
Provides-Extra: optimizers
Requires-Dist: galore_torch; extra == "optimizers"
Requires-Dist: apollo-torch; extra == "optimizers"
Requires-Dist: lomo-optim==0.1.1; extra == "optimizers"
Requires-Dist: torch-optimi==0.2.1; extra == "optimizers"
Requires-Dist: came_pytorch==0.1.3; extra == "optimizers"
Provides-Extra: ray
Requires-Dist: ray[train]; extra == "ray"
Provides-Extra: vllm
Requires-Dist: vllm==0.8.5.post1; extra == "vllm"
Provides-Extra: llmcompressor
Requires-Dist: llmcompressor==0.5.1; extra == "llmcompressor"
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist

<p align="center">
    <picture>
        <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/axolotl-ai-cloud/axolotl/887513285d98132142bf5db2a74eb5e0928787f1/image/axolotl_logo_digital_white.svg">
        <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/axolotl-ai-cloud/axolotl/887513285d98132142bf5db2a74eb5e0928787f1/image/axolotl_logo_digital_black.svg">
        <img alt="Axolotl" src="https://raw.githubusercontent.com/axolotl-ai-cloud/axolotl/887513285d98132142bf5db2a74eb5e0928787f1/image/axolotl_logo_digital_black.svg" width="400" height="104" style="max-width: 100%;">
    </picture>
</p>

<p align="center">
    <img src="https://img.shields.io/github/license/axolotl-ai-cloud/axolotl.svg?color=blue" alt="GitHub License">
    <img src="https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/tests.yml/badge.svg" alt="tests">
    <a href="https://codecov.io/gh/axolotl-ai-cloud/axolotl"><img src="https://codecov.io/gh/axolotl-ai-cloud/axolotl/branch/main/graph/badge.svg" alt="codecov"></a>
    <a href="https://github.com/axolotl-ai-cloud/axolotl/releases"><img src="https://img.shields.io/github/release/axolotl-ai-cloud/axolotl.svg" alt="Releases"></a>
    <br/>
    <a href="https://github.com/axolotl-ai-cloud/axolotl/graphs/contributors"><img src="https://img.shields.io/github/contributors-anon/axolotl-ai-cloud/axolotl?color=yellow&style=flat-square" alt="contributors" style="height: 20px;"></a>
    <img src="https://img.shields.io/github/stars/axolotl-ai-cloud/axolotl" alt="GitHub Repo stars">
    <br/>
    <a href="https://discord.com/invite/HhrNrHJPRb"><img src="https://img.shields.io/badge/discord-7289da.svg?style=flat-square&logo=discord" alt="discord" style="height: 20px;"></a>
    <a href="https://twitter.com/axolotl_ai"><img src="https://img.shields.io/twitter/follow/axolotl_ai?style=social" alt="twitter" style="height: 20px;"></a>
    <br/>
    <img src="https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/tests-nightly.yml/badge.svg" alt="tests-nightly">
    <img src="https://github.com/axolotl-ai-cloud/axolotl/actions/workflows/multi-gpu-e2e.yml/badge.svg" alt="multigpu-semi-weekly tests">
</p>


## üéâ Latest Updates

- 2025/06: Magistral with mistral-common tokenizer support has been added to Axolotl. See [examples](https://github.com/axolotl-ai-cloud/axolotl/tree/main/examples/magistral) to start training your own Magistral models with Axolotl!
- 2025/05: Quantization Aware Training (QAT) support has been added to Axolotl. Explore the [docs](https://docs.axolotl.ai/docs/qat.html) to learn more!
- 2025/04: Llama 4 support has been added in Axolotl. See [examples](https://github.com/axolotl-ai-cloud/axolotl/tree/main/examples/llama-4) to start training your own Llama 4 models with Axolotl's linearized version!
- 2025/03: Axolotl has implemented Sequence Parallelism (SP) support. Read the [blog](https://huggingface.co/blog/axolotl-ai-co/long-context-with-sequence-parallelism-in-axolotl) and [docs](https://docs.axolotl.ai/docs/sequence_parallelism.html) to learn how to scale your context length when fine-tuning.
- 2025/03: (Beta) Fine-tuning Multimodal models is now supported in Axolotl. Check out the [docs](https://docs.axolotl.ai/docs/multimodal.html) to fine-tune your own!
- 2025/02: Axolotl has added LoRA optimizations to reduce memory usage and improve training speed for LoRA and QLoRA in single GPU and multi-GPU training (DDP and DeepSpeed). Jump into the [docs](https://docs.axolotl.ai/docs/lora_optims.html) to give it a try.
- 2025/02: Axolotl has added GRPO support. Dive into our [blog](https://huggingface.co/blog/axolotl-ai-co/training-llms-w-interpreter-feedback-wasm) and [GRPO example](https://github.com/axolotl-ai-cloud/grpo_code) and have some fun!
- 2025/01: Axolotl has added Reward Modelling / Process Reward Modelling fine-tuning support. See [docs](https://docs.axolotl.ai/docs/reward_modelling.html).

## ‚ú® Overview

Axolotl is a tool designed to streamline post-training for various AI models.

Features:

- **Multiple Model Support**: Train various models like LLaMA, Mistral, Mixtral, Pythia, and more. We are compatible with HuggingFace transformers causal language models.
- **Training Methods**: Full fine-tuning, LoRA, QLoRA, GPTQ, QAT, Preference Tuning (DPO, IPO, KTO, ORPO), RL (GRPO), Multimodal, and Reward Modelling (RM) / Process Reward Modelling (PRM).
- **Easy Configuration**: Re-use a single YAML file between dataset preprocess, training, evaluation, quantization, and inference.
- **Performance Optimizations**: [Multipacking](https://docs.axolotl.ai/docs/multipack.html), [Flash Attention](https://github.com/Dao-AILab/flash-attention), [Xformers](https://github.com/facebookresearch/xformers), [Flex Attention](https://pytorch.org/blog/flexattention/), [Liger Kernel](https://github.com/linkedin/Liger-Kernel), [Cut Cross Entropy](https://github.com/apple/ml-cross-entropy/tree/main), [Sequence Parallelism (SP)](https://docs.axolotl.ai/docs/sequence_parallelism.html), [LoRA optimizations](https://docs.axolotl.ai/docs/lora_optims.html), [Multi-GPU training (FSDP1, FSDP2, DeepSpeed)](https://docs.axolotl.ai/docs/multi-gpu.html), [Multi-node training (Torchrun, Ray)](https://docs.axolotl.ai/docs/multi-node.html), and many more!
- **Flexible Dataset Handling**: Load from local, HuggingFace, and cloud (S3, Azure, GCP, OCI) datasets.
- **Cloud Ready**: We ship [Docker images](https://hub.docker.com/u/axolotlai) and also [PyPI packages](https://pypi.org/project/axolotl/) for use on cloud platforms and local hardware.



## üöÄ Quick Start

**Requirements**:

- NVIDIA GPU (Ampere or newer for `bf16` and Flash Attention) or AMD GPU
- Python 3.11
- PyTorch ‚â•2.5.1

### Installation

#### Using pip

```bash
pip3 install -U packaging==23.2 setuptools==75.8.0 wheel ninja
pip3 install --no-build-isolation axolotl[flash-attn,deepspeed]

# Download example axolotl configs, deepspeed configs
axolotl fetch examples
axolotl fetch deepspeed_configs  # OPTIONAL
```

#### Using Docker

Installing with Docker can be less error prone than installing in your own environment.
```bash
docker run --gpus '"all"' --rm -it axolotlai/axolotl:main-latest
```

Other installation approaches are described [here](https://docs.axolotl.ai/docs/installation.html).

### Your First Fine-tune

```bash
# Fetch axolotl examples
axolotl fetch examples

# Or, specify a custom path
axolotl fetch examples --dest path/to/folder

# Train a model using LoRA
axolotl train examples/llama-3/lora-1b.yml
```

That's it! Check out our [Getting Started Guide](https://docs.axolotl.ai/docs/getting-started.html) for a more detailed walkthrough.


## üìö Documentation

- [Installation Options](https://docs.axolotl.ai/docs/installation.html) - Detailed setup instructions for different environments
- [Configuration Guide](https://docs.axolotl.ai/docs/config-reference.html) - Full configuration options and examples
- [Dataset Loading](https://docs.axolotl.ai/docs/dataset_loading.html) - Loading datasets from various sources
- [Dataset Guide](https://docs.axolotl.ai/docs/dataset-formats/) - Supported formats and how to use them
- [Multi-GPU Training](https://docs.axolotl.ai/docs/multi-gpu.html)
- [Multi-Node Training](https://docs.axolotl.ai/docs/multi-node.html)
- [Multipacking](https://docs.axolotl.ai/docs/multipack.html)
- [API Reference](https://docs.axolotl.ai/docs/api/) - Auto-generated code documentation
- [FAQ](https://docs.axolotl.ai/docs/faq.html) - Frequently asked questions

## ü§ù Getting Help

- Join our [Discord community](https://discord.gg/HhrNrHJPRb) for support
- Check out our [Examples](https://github.com/axolotl-ai-cloud/axolotl/tree/main/examples/) directory
- Read our [Debugging Guide](https://docs.axolotl.ai/docs/debugging.html)
- Need dedicated support? Please contact [‚úâÔ∏èwing@axolotl.ai](mailto:wing@axolotl.ai) for options

## üåü Contributing

Contributions are welcome! Please see our [Contributing Guide](https://github.com/axolotl-ai-cloud/axolotl/blob/main/.github/CONTRIBUTING.md) for details.

## ‚ù§Ô∏è Sponsors

Thank you to our sponsors who help make Axolotl possible:

- [Modal](https://www.modal.com?utm_source=github&utm_medium=github&utm_campaign=axolotl) - Modal lets you run
jobs in the cloud, by just writing a few lines of Python. Customers use Modal to deploy Gen AI models at large scale,
fine-tune large language models, run protein folding simulations, and much more.

Interested in sponsoring? Contact us at [wing@axolotl.ai](mailto:wing@axolotl.ai)

## üìú License

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.
